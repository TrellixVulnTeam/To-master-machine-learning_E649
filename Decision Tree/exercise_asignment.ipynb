{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the approximate depth of a Decision Tree trained (without restrictions) on a training set with 1 million instances?\n",
    "+ The depth of a well-balanced binary tree containing m leaves is equal to log2(m), rounded up.\n",
    "+ Thus, if the training set contains one million instances, the Decision Tree will have a depth of log2\n",
    "(106) ≈ 20 (actually a bit more since the tree will generally not be perfectly well balanced)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Is a node’s Gini impurity generally lower or greater than its parent’s? Is it generally lower/greater, or always lower/greater?\n",
    "+ Tạp chất Gini của một nút thường thấp hơn tạp chất của nút cha của nó. Điều này được đảm bảo bởi hàm chi phí của thuật toán đào tạo CART, hàm này chia nhỏ từng nút theo cách giảm thiểu tổng trọng số của các tạp chất Gini con của nó. Tuy nhiên, nếu một con nhỏ hơn con kia, thì nó có thể có tạp chất Gini cao hơn cha mẹ của nó, miễn là sự gia tăng này nhiều hơn được bù đắp bởi sự giảm tạp chất của con kia.\n",
    "+ A node's Gini impurity is generally lower than its parent's. This is ensured by the CART training algorithm's cost function, which splits each node in a way that minimizes the weighted sum of its children's Gini impurities. However, if one child is smaller than the other, it is possible for it to have a higher Gini impurity than its parent, as long as this increase is more than compensated for by a decrease of the other child's impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If a Decision Tree is overfitting the training set, is it a good idea to try decreasing max_depth?\n",
    "+ If a Decision Tree is overfitting the training set, it may be a good idea to decrease max_depth, since this will constrain the model, regularizing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features?\n",
    "+ Decision Trees don't care whether or not the training data is scaled or centered; scaling the input features will just be a waste of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Nếu mất một giờ để huấn luyện Cây quyết định trên một tập huấn luyện chứa 1 triệu trường hợp, thì khoảng bao nhiêu thời gian để huấn luyện một Cây quyết định khác trên tập huấn luyện chứa 10 triệu trường hợp?\n",
    "+ The computational complexity of training a Decision Tree is O(n × m log(m)). So if you multiply the training set size by 10, the training time will be multiplied by K = (n × 10m × log(10m)) / (n × m × log(m)) = 10 × log(10m) / log(m). If m = 10^6, then K ≈ 11.7, so you can expect the training time to be roughly 11.7 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. If your training set contains 100,000 instances, will setting presort=True speed\n",
    "up training?\n",
    "+ Presorting the training set speeds up raining only if the dataset is smaller than a few thousand instances. If it contains 100,000 instances, setting presort=True will considerably slow down training. \n",
    "+ Việc lưu trữ tập hợp đào tạo chỉ tăng tốc độ mưa nếu tập dữ liệu nhỏ hơn vài nghìn trường hợp. Nếu nó chứa 100.000 phiên bản, việc đặt presort = True sẽ làm chậm quá trình đào tạo đáng kể."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Train and fine-tune a Decision Tree for the moons dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X,y = make_moons(n_samples=10000, noise=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for training and evalue model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_leaf_nodes&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_leaf_nodes&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...],\n",
       "                         'min_samples_split': [2, 3, 4]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = {'max_leaf_nodes':list(range(2,100)), 'min_samples_split':[2,3,4]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_leaf_nodes=18, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_leaf_nodes=18, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_leaf_nodes=18, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1013\n",
      "           1       0.93      0.92      0.93       987\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.93      0.93      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "score = classification_report(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Grow a forest.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "n_trees = 100\n",
    "n_instance = 100\n",
    "\n",
    "mini_sets = []\n",
    "# test_size = so luong mau thu nghiem tuyet doi\n",
    "sp = ShuffleSplit(n_splits=1000, test_size = len(X_train) - n_instance, random_state=42) \n",
    "\n",
    "for mini_train_index, mini_test_index in sp.split(X_train):\n",
    "    X_mini_train = X_train[mini_train_index]\n",
    "    y_mini_train = y_train[mini_train_index]\n",
    "    mini_sets.append((X_mini_train, y_mini_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train one Decision Tree on each subset, using the best hyperparameter values found above. Evaluate these 1,000 Decision Trees on the test set. Since they were trained on smaller sets, these Decision Trees will likely perform worse than the first Decision Tree, achieving only about 80% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8675200000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "forest = [clone(grid_search_cv.best_estimator_) for _ in range(n_trees)]\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
    "    tree.fit(X_mini_train, y_mini_train)\n",
    "    \n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Now comes the magic. For each test set instance, generate the predictions of the 1,000 Decision Trees, and keep only the most frequent prediction (you can use SciPy's `mode()` function for this). This gives you _majority-vote predictions_ over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42),\n",
       " DecisionTreeClassifier(max_leaf_nodes=18, random_state=42)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)\n",
    "\n",
    "for tree_index, tree in enumerate(forest):\n",
    "    Y_pred[tree_index] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('envML': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fc21d9c106b72898f1c3f59990c72129bde1177026ea4c3bb6a4f06e68dcc6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
