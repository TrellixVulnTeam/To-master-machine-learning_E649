{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the approximate depth of a Decision Tree trained (without restrictions) on a training set with 1 million instances?\n",
    "+ The depth of a well-balanced binary tree containing m leaves is equal to log2(m), rounded up.\n",
    "+ Thus, if the training set contains one million instances, the Decision Tree will have a depth of log2\n",
    "(106) ≈ 20 (actually a bit more since the tree will generally not be perfectly well balanced)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Is a node’s Gini impurity generally lower or greater than its parent’s? Is it generally lower/greater, or always lower/greater?\n",
    "+ Tạp chất Gini của một nút thường thấp hơn tạp chất của nút cha của nó. Điều này được đảm bảo bởi hàm chi phí của thuật toán đào tạo CART, hàm này chia nhỏ từng nút theo cách giảm thiểu tổng trọng số của các tạp chất Gini con của nó. Tuy nhiên, nếu một con nhỏ hơn con kia, thì nó có thể có tạp chất Gini cao hơn cha mẹ của nó, miễn là sự gia tăng này nhiều hơn được bù đắp bởi sự giảm tạp chất của con kia.\n",
    "+ A node's Gini impurity is generally lower than its parent's. This is ensured by the CART training algorithm's cost function, which splits each node in a way that minimizes the weighted sum of its children's Gini impurities. However, if one child is smaller than the other, it is possible for it to have a higher Gini impurity than its parent, as long as this increase is more than compensated for by a decrease of the other child's impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If a Decision Tree is overfitting the training set, is it a good idea to try decreasing max_depth?\n",
    "+ If a Decision Tree is overfitting the training set, it may be a good idea to decrease max_depth, since this will constrain the model, regularizing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features?\n",
    "+ Decision Trees don't care whether or not the training data is scaled or centered; scaling the input features will just be a waste of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Nếu mất một giờ để huấn luyện Cây quyết định trên một tập huấn luyện chứa 1 triệu trường hợp, thì khoảng bao nhiêu thời gian để huấn luyện một Cây quyết định khác trên tập huấn luyện chứa 10 triệu trường hợp?\n",
    "+ The computational complexity of training a Decision Tree is O(n × m log(m)). So if you multiply the training set size by 10, the training time will be multiplied by K = (n × 10m × log(10m)) / (n × m × log(m)) = 10 × log(10m) / log(m). If m = 10^6, then K ≈ 11.7, so you can expect the training time to be roughly 11.7 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. If your training set contains 100,000 instances, will setting presort=True speed\n",
    "up training?\n",
    "+ Presorting the training set speeds up raining only if the dataset is smaller than a few thousand instances. If it contains 100,000 instances, setting presort=True will considerably slow down training. \n",
    "+ Việc lưu trữ tập hợp đào tạo chỉ tăng tốc độ mưa nếu tập dữ liệu nhỏ hơn vài nghìn trường hợp. Nếu nó chứa 100.000 phiên bản, việc đặt presort = True sẽ làm chậm quá trình đào tạo đáng kể."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Train and fine-tune a Decision Tree for the moons dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X,y = make_moons(n_samples=10000, noise=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for training and evalue model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('envML': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fc21d9c106b72898f1c3f59990c72129bde1177026ea4c3bb6a4f06e68dcc6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
